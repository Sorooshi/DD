{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587852fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import defaultdict \n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b3ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from dd_package.data.dyslexia_data import DyslexiaData\n",
    "from dd_package.data.preprocess import preprocess_data\n",
    "\n",
    "from dd_package.models.regression_estimators import RegressionEstimators\n",
    "from dd_package.models.classification_estimators import ClassificationEstimators\n",
    "\n",
    "from dd_package.common.utils import save_a_dict, load_a_dict, print_the_evaluated_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43eb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "configs = {\n",
    "    \"models_path\": Path(\"/home/soroosh/Programmes/DD/Models\"),\n",
    "    \"results_path\": Path(\"/home/soroosh/Programmes/DD/Results\"),\n",
    "    \"figures_path\": Path(\"/home/soroosh/Programmes/DD/Figures\"),\n",
    "    \"params_path\": Path(\"/home/soroosh/Programmes/DD//Params\"),\n",
    "    \"n_repeats\": 10,\n",
    "    \"n_splits\": 5,\n",
    "}\n",
    "\n",
    "configs = SimpleNamespace(**configs)\n",
    "\n",
    "estimator_name = \"SV_cls\"\n",
    "data_name = \"DD_demo\"\n",
    "to_shuffle = True\n",
    "learning_method = \"classification\"\n",
    "\n",
    "specifier = data_name+\"-\"+estimator_name+\"-\"+str(to_shuffle)\n",
    "configs.specifier = specifier\n",
    "configs.data_name = data_name\n",
    "configs.name_wb = data_name+\": \"+specifier\n",
    "configs.learning_method = learning_method\n",
    "# configs.project = \"DD_test\"\n",
    "# configs.group = \"debug\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dd = DyslexiaData(path=\"../../datasets/\", n_repeats=5)\n",
    "\n",
    "\n",
    "\n",
    "demos = dd.get_demo_datasets()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e32f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demo = dd.concat_classes_demo()  # .reset_index(drop=True)\n",
    "\n",
    "demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55379d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_org, y_org = dd.get_onehot_features_targets(\n",
    "        data=demo,\n",
    "        c_features= [\"Sex\", \"Grade\", ],  # \n",
    "        indicators=[\"SubjectID\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19360866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x , x_df = dd.get_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb641245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55078b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c1 = x[1, :].reshape(1, -1)\n",
    "c2 = x[52, :].reshape(1, -1)\n",
    "c3 = x[111, :].reshape(1, -1)\n",
    "centroids = jnp.concatenate((c1, c2, c3), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean(datapoint, centroid,):\n",
    "    return jax.tree_leaves(jnp.sum(jnp.power(datapoint - centroid, 2), axis=1))[0]\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return jax.tree_leaves(jnp.all(jnp.linalg.eigvals(x) > 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab376e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f98c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = data.shape[0]\n",
    "n_clusters = centroids.shape[0]\n",
    "distance_fn = compute_euclidean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bacc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eae56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = dd.get_stratified_kfold_cv(\n",
    "    to_shuffle=to_shuffle,\n",
    "    n_splits=configs.n_splits,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c09e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = y_org.Group.values\n",
    "\n",
    "\n",
    "\n",
    "# y = preprocess_data(x=y, pp='mm')  # only x is standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0564a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_iter = True \n",
    "n_iter = 0\n",
    "n_iters = 400\n",
    "tol_m = 1e-2\n",
    "tol_g = 1e-3\n",
    "clusters = jnp.zeros([n_nodes]) + jnp.inf\n",
    "\n",
    "grads_sums = []\n",
    "aris_history = []\n",
    "grads_history = []\n",
    "hessians_history = []\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "step_size = 2e-1\n",
    "c_iter = 0\n",
    "\n",
    "\n",
    "while f_iter: \n",
    "    \n",
    "    # cluster assingment \n",
    "    for i in range(n_nodes):   \n",
    "        distances = distance_fn(datapoint=x[i, :], centroid=centroids)\n",
    "        clusters = clusters.at[i].set(jnp.argmin(distances, axis=0))\n",
    "        \n",
    "    previous_clusters = deepcopy(clusters)\n",
    "    \n",
    "    # cluster update\n",
    "    tmp_grads, tmp_hess = [], []\n",
    "    for k in range(n_clusters):\n",
    "        \n",
    "        cluster_data = jnp.mean(x[jnp.where(clusters==k)[0], :], axis=0).reshape(1, -1)\n",
    "        \n",
    "        # Gradient of the distance function w.r.t the closest center \n",
    "        grads = jax.jacfwd(distance_fn, argnums=(1,))(cluster_data, centroids[k, :])\n",
    "        grads = jax.tree_leaves(grads)[0]\n",
    "        \n",
    "        # Upgate centrods\n",
    "        updated_centeroid = centroids[k, :] - step_size * grads\n",
    "        centroids = centroids.at[k].set(updated_centeroid[0])\n",
    "        \n",
    "        # Convergence check\n",
    "        # FONC: First Order Necessary Condition\n",
    "        l2_norm_grads= jnp.sqrt(jnp.sum(jnp.power(grads, 2)))\n",
    "        tmp_grads.append(l2_norm_grads)\n",
    "\n",
    "        # SONC: Second Order Necessary Condition\n",
    "        # Jaccobian of gradients (hessian matrix) of the distance function w.r.t the closest center \n",
    "        hessian_mat = jax.hessian(distance_fn, argnums=(1,))(cluster_data, centroids[k, :])\n",
    "        hessian_mat = jax.tree_leaves(hessian_mat)[0]\n",
    "        if jnp.all(is_pos_def(hessian_mat[0])[0]):\n",
    "            tmp_hess.append(1)\n",
    "        else:\n",
    "            tmp_hess.append(0)\n",
    "\n",
    "    \n",
    "    ave_l2_norms_grads = jnp.asarray(tmp_grads).mean()\n",
    "    grads_history.append(ave_l2_norms_grads)\n",
    "    \n",
    "    ave_semi_pos_def_check = jnp.asarray(tmp_hess).mean()\n",
    "    hessians_history.append(ave_semi_pos_def_check)\n",
    "    \n",
    "    ari = metrics.adjusted_rand_score(y, clusters)\n",
    "\n",
    "    print(\n",
    "        f\"n_iter = {n_iter} ari={ari:.3f} f_iter={f_iter} ave_l2_norms_grads = {ave_l2_norms_grads:.3f}\" \n",
    "    )\n",
    "    \n",
    "    \n",
    "    # FOCN and SOCN    \n",
    "    if ave_semi_pos_def_check ==1. and ave_l2_norms_grads <= tol_g:\n",
    "        print(\"ave_l2_norms_grads:\", ave_l2_norms_grads)\n",
    "        print(\"An optimum has found! stoped by FONC and SONC\")\n",
    "        print(\"ARI:\",ari)\n",
    "\n",
    "        if jnp.all(previous_clusters == clusters):\n",
    "            f_iter = False\n",
    "            print(\"Converge by two consequitive cluster recovery results conincidence\")            \n",
    "            print(f\"node {i} ARI {ari}\")\n",
    "            break\n",
    "    \n",
    "    n_iter += 1\n",
    "    \n",
    "    if n_iter >= n_iters:\n",
    "        f_iter = False\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = dd.get_stratified_train_test_splits(\n",
    "    x=x, y=y,\n",
    "    labels=y_org.Group.values,\n",
    "    to_shuffle=to_shuffle,\n",
    "    n_splits=configs.n_repeats\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg_est = ClassificationEstimators(\n",
    "    x=x, y=y, cv=cv, data=data,\n",
    "    estimator_name=estimator_name,\n",
    "    configs=configs,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51cb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc374aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg_est.instantiate_tuning_estimator_and_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg_est.tune_hyper_parameters()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg_est.instantiate_train_test_estimator()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_est.train_test_tuned_estimator()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84613055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reg_est.save_params_results()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df34305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_est.print_results()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5efa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0723825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "res = load_a_dict(name=\"DD_demo-L_cls-True_TEST\",\n",
    "                  save_path=\"/home/soroosh/Programmes/DD/Results/\")\n",
    "\n",
    "\n",
    "print_the_evaluated_results(results=res, learning_method=\"classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for k, v in res.items():\n",
    "    print(\"probs:\", v[\"y_pred_prob\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21494360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b7f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4404936",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude_at_risk = False\n",
    "\n",
    "# dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "_ = dd.get_demo_datasets()  # demos and phonological (which is initially part of demo)\n",
    "demo_phono = dd.concat_classes_demo()\n",
    "\n",
    "# The optimize way to exclude at-risk class\n",
    "if to_exclude_at_risk == 1:\n",
    "    to_exclude_at_risk = True\n",
    "    demo_phono = demo_phono.loc[demo_phono.Group != 2]\n",
    "\n",
    "df_data_to_use = demo_phono.loc[:, [\n",
    "                                       'Group', 'SubjectID', 'Sound_detection', 'Sound_change', 'Reading_speed'\n",
    "                                   ]]\n",
    "c_features = None\n",
    "indicators = ['SubjectID', ]\n",
    "targets = [\"Group\", \"Reading_speed\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e68f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebccb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude_at_risk = True\n",
    "\n",
    "# dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "_ = dd.get_demo_datasets()  # demos and phonological (which is initially part of demo)\n",
    "demo_phono = dd.concat_classes_demo()\n",
    "\n",
    "# The optimize way to exclude at-risk class\n",
    "if to_exclude_at_risk == 1:\n",
    "    to_exclude_at_risk = True\n",
    "    demo_phono = demo_phono.loc[demo_phono.Group != 2]\n",
    "\n",
    "df_data_to_use = demo_phono.loc[:, [\n",
    "                                       'Group', 'SubjectID', 'Sound_detection', 'Sound_change', 'Reading_speed'\n",
    "                                   ]]\n",
    "c_features = None\n",
    "indicators = ['SubjectID', ]\n",
    "targets = [\"Group\", \"Reading_speed\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef94ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_data_to_use.Group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ff111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Jan2022",
   "language": "python",
   "name": "venv_jan2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
