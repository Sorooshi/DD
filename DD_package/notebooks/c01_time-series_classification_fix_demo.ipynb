{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9d2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import shap \n",
    "import pickle\n",
    "import sklearn \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aaee449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a8aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from dd_package.data.dyslexia_data import DyslexiaData\n",
    "from dd_package.data.preprocess import preprocess_data\n",
    "\n",
    "from dd_package.models.regression_estimators import RegressionEstimators\n",
    "\n",
    "from dd_package.common.utils import save_a_dict, load_a_dict, print_the_evaluated_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0c1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs = {\n",
    "    \"models_path\": Path(\"/home/soroosh/Programmes/DD/Models\"),\n",
    "    \"results_path\": Path(\"/home/soroosh/Programmes/DD/Results\"),\n",
    "    \"figures_path\": Path(\"/home/soroosh/Programmes/DD/Figures\"),\n",
    "    \"params_path\": Path(\"/home/soroosh/Programmes/DD//Params\"),\n",
    "    \"n_repeats\": 10,\n",
    "    \"n_splits\": 5,\n",
    "}\n",
    "\n",
    "configs = SimpleNamespace(**configs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bf7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_name=\"dd_fix_demo\"\n",
    "\n",
    "estimator_name = \"tknn_cls\"\n",
    "to_shuffle = False\n",
    "to_exclude_at_risk = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27a1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "specifier = data_name + \"-\" + estimator_name + \\\n",
    "\"--shuffled:\" + str(to_shuffle) + \\\n",
    "\"--exclude at risk:\" + str(to_exclude_at_risk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a10bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.specifier = specifier\n",
    "configs.data_name = data_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a569c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dd_fix_demo-tknn_cls--shuffled:False--exclude at risk:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "configs.specifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334f200",
   "metadata": {},
   "source": [
    "# demo-Fcls-mm:\n",
    "\n",
    "- Chosen model: **MLP**\n",
    "\n",
    "\n",
    "\n",
    "https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f70fb3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b8b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dd = DyslexiaData(path=\"../../datasets/\", n_repeats=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae3f4789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Demo data: \n",
      "  dyslexia (72, 9)\n",
      "  norm (213, 9)\n",
      "  risk (22, 9)\n",
      " \n",
      "Loading Fixation report data:\n",
      "  dyslexia (59770, 7)\n",
      "  norm (139507, 7)\n",
      "  risk (26073, 7)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if data_name == \"dd_demo\":\n",
    "    # dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "    _ = dd.get_demo_datasets()  # demos and phonological (which is initially part of demo)\n",
    "    demo_phono = dd.concat_classes_demo()\n",
    "\n",
    "    # The optimize way to exclude at-risk class\n",
    "    if to_exclude_at_risk == 1:\n",
    "        to_exclude_at_risk = True\n",
    "        demo_phono = demo_phono.loc[demo_phono.Group != 2]\n",
    "\n",
    "    df_data_to_use = demo_phono.loc[:, [\n",
    "                                           'Group', 'SubjectID', 'Sex', 'Grade', 'Age', 'IQ', 'Reading_speed',\n",
    "                                       ]]\n",
    "    c_features = ['Sex', 'Grade', ]\n",
    "    indicators = ['SubjectID', ]\n",
    "    targets = [\"Group\", \"Reading_speed\", ]\n",
    "\n",
    "elif data_name == \"dd_fix_demo\":\n",
    "    # dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "    _ = dd.get_demo_datasets()  # demos\n",
    "    _ = dd.get_fix_datasets()  # fixes\n",
    "\n",
    "    # concatenate pd.dfs to a pd.df\n",
    "    fix = dd.concat_classes_fix()\n",
    "    demo_phono = dd.concat_classes_demo()\n",
    "\n",
    "    # The optimize way to exclude at-risk class\n",
    "    if to_exclude_at_risk == 1:\n",
    "        to_exclude_at_risk = True\n",
    "        fix = fix.loc[fix.Group != 2]\n",
    "        demo_phono = demo_phono.loc[demo_phono.Group != 2]\n",
    "\n",
    "    fix_demo = dd.concat_dfs(\n",
    "        df1=fix,\n",
    "        df2=demo_phono,\n",
    "        features1=fix.columns,\n",
    "        features2=[\n",
    "            \"Sex\", \"Grade\", \"Age\", \"IQ\", \"Reading_speed\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df_data_to_use = fix_demo\n",
    "    c_features = ['Sex', 'Grade', ]\n",
    "    indicators = [\n",
    "        'SubjectID', 'Sentence_ID', 'Word_Number',\n",
    "    ]\n",
    "\n",
    "    targets = [\"Group\", \"Reading_speed\", ]\n",
    "    \n",
    "elif data_name == \"dd_fix\":\n",
    "\n",
    "    # dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "    _ = dd.get_fix_datasets()  # fixes\n",
    "    # concatenate pd.dfs to a pd.df\n",
    "    fix = dd.concat_classes_fix()\n",
    "\n",
    "    # The optimize way to exclude at-risk class\n",
    "    if to_exclude_at_risk == 1:\n",
    "        to_exclude_at_risk = True\n",
    "        fix = fix.loc[fix.Group != 2]\n",
    "\n",
    "    df_data_to_use = fix\n",
    "    c_features = None\n",
    "    indicators = [\n",
    "        'SubjectID', 'Sentence_ID', 'Word_Number',\n",
    "    ]\n",
    "\n",
    "    targets = [\"Group\", ]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c67800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Word_Number</th>\n",
       "      <th>FIX_X</th>\n",
       "      <th>FIX_Y</th>\n",
       "      <th>FIX_DURATION</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Age</th>\n",
       "      <th>IQ</th>\n",
       "      <th>Reading_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>177.3</td>\n",
       "      <td>531.8</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>200.5</td>\n",
       "      <td>545.2</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>282.7</td>\n",
       "      <td>542.4</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>358.1</td>\n",
       "      <td>545.5</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>392.8</td>\n",
       "      <td>536.3</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group SubjectID  Sentence_ID  Word_Number  FIX_X  FIX_Y  FIX_DURATION  Sex  \\\n",
       "0      1        10            4            1  177.3  531.8         219.0    1   \n",
       "1      1        10            4            2  200.5  545.2         247.0    1   \n",
       "2      1        10            4            3  282.7  542.4         261.0    1   \n",
       "3      1        10            4            4  358.1  545.5         268.0    1   \n",
       "4      1        10            4            4  392.8  536.3         129.0    1   \n",
       "\n",
       "   Grade  Age  IQ  Reading_speed  \n",
       "0      4   10  23          102.0  \n",
       "1      4   10  23          102.0  \n",
       "2      4   10  23          102.0  \n",
       "3      4   10  23          102.0  \n",
       "4      4   10  23          102.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_data_to_use.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa773a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_org, y_org = dd.get_onehot_features_targets(\n",
    "    data=df_data_to_use,\n",
    "    c_features=c_features,\n",
    "    indicators=indicators,\n",
    "    targets=targets,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee1201d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIX_X</th>\n",
       "      <th>FIX_Y</th>\n",
       "      <th>Age</th>\n",
       "      <th>Grade_6</th>\n",
       "      <th>Sex_2</th>\n",
       "      <th>Grade_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Grade_5</th>\n",
       "      <th>FIX_DURATION</th>\n",
       "      <th>Grade_1</th>\n",
       "      <th>Grade_4</th>\n",
       "      <th>IQ</th>\n",
       "      <th>Grade_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.3</td>\n",
       "      <td>531.8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.5</td>\n",
       "      <td>545.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282.7</td>\n",
       "      <td>542.4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358.1</td>\n",
       "      <td>545.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392.8</td>\n",
       "      <td>536.3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIX_X  FIX_Y  Age  Grade_6  Sex_2  Grade_3  Sex_1  Grade_5  FIX_DURATION  \\\n",
       "0  177.3  531.8   10        0      0        0      1        0         219.0   \n",
       "1  200.5  545.2   10        0      0        0      1        0         247.0   \n",
       "2  282.7  542.4   10        0      0        0      1        0         261.0   \n",
       "3  358.1  545.5   10        0      0        0      1        0         268.0   \n",
       "4  392.8  536.3   10        0      0        0      1        0         129.0   \n",
       "\n",
       "   Grade_1  Grade_4  IQ  Grade_2  \n",
       "0        0        1  23        0  \n",
       "1        0        1  23        0  \n",
       "2        0        1  23        0  \n",
       "3        0        1  23        0  \n",
       "4        0        1  23        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_org.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea6efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(x_org.Sex_1.values.shape[0]):\n",
    "#     print(x_org.Sex_1.values[i], x_org.Sex_2.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4beffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Reading_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group  Reading_speed\n",
       "0      1          102.0\n",
       "1      1          102.0\n",
       "2      1          102.0\n",
       "3      1          102.0\n",
       "4      1          102.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_org.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab4345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_method: classification\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if estimator_name.split(\"_\")[-1] == \"reg\":\n",
    "    learning_method = \"regression\"\n",
    "    y = y_org.Reading_speed.values\n",
    "\n",
    "elif estimator_name.split(\"_\")[-1] == \"cls\":\n",
    "    learning_method = \"classification\"\n",
    "    y = y_org.Group.values\n",
    "\n",
    "elif estimator_name.split(\"_\")[-1] == \"clu\":\n",
    "    from dd_package.models.clustering_estimators import ClusteringEstimators\n",
    "    y = y_org.Group.values\n",
    "else:\n",
    "    assert False, \"Undefined algorithm and thus undefined target values\"\n",
    "    \n",
    "print(\"learning_method:\", learning_method)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25adc324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing: mm\n",
      "Preprocessed data shape: (225350, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = preprocess_data(x=x_org, pp=\"mm\")  # only x is standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc3d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = dd.get_stratified_train_test_splits(\n",
    "        x=x, y=y,\n",
    "        labels=y_org.Group.values,\n",
    "        to_shuffle=to_shuffle,\n",
    "        n_splits=10\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0a9117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.defaultdict,\n",
       "            {'1': defaultdict(list,\n",
       "                         {'x_train': array([[0.098, 0.538, 0.375, ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.179, 0.55 , 0.375, ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.221, 0.527, 0.375, ..., 0.   , 0.81 , 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.305, 0.461, 0.75 , ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.436, 0.482, 0.75 , ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.422, 0.498, 0.75 , ..., 0.   , 0.905, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([1, 1, 1, ..., 2, 2, 2])}),\n",
       "             '2': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.098, 0.538, 0.375, ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.179, 0.55 , 0.375, ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.221, 0.527, 0.375, ..., 0.   , 0.81 , 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.262, 0.481, 0.25 , ..., 0.   , 0.952, 1.   ],\n",
       "                                 [0.25 , 0.795, 0.25 , ..., 0.   , 0.952, 1.   ],\n",
       "                                 [0.247, 0.635, 0.25 , ..., 0.   , 0.952, 1.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([1, 1, 1, ..., 2, 2, 2])}),\n",
       "             '3': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.732, 0.499, 0.5  , ..., 1.   , 0.667, 0.   ],\n",
       "                                 [0.757, 0.495, 0.5  , ..., 1.   , 0.667, 0.   ],\n",
       "                                 [0.734, 0.479, 0.5  , ..., 1.   , 0.667, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.289, 0.448, 0.125, ..., 0.   , 0.667, 0.   ],\n",
       "                                 [0.302, 0.465, 0.125, ..., 0.   , 0.667, 0.   ],\n",
       "                                 [0.319, 0.47 , 0.125, ..., 0.   , 0.667, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([1, 1, 1, ..., 2, 2, 2])}),\n",
       "             '4': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.464, 0.476, 0.25 , ..., 0.   , 0.524, 1.   ],\n",
       "                                 [0.462, 0.453, 0.25 , ..., 0.   , 0.524, 1.   ],\n",
       "                                 [0.462, 0.481, 0.25 , ..., 0.   , 0.524, 1.   ],\n",
       "                                 ...,\n",
       "                                 [0.542, 0.535, 0.125, ..., 0.   , 0.619, 0.   ],\n",
       "                                 [0.574, 0.523, 0.125, ..., 0.   , 0.619, 0.   ],\n",
       "                                 [0.595, 0.53 , 0.125, ..., 0.   , 0.619, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([3, 3, 3, ..., 2, 2, 2])}),\n",
       "             '5': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.433, 0.467, 0.125, ..., 0.   , 0.857, 1.   ],\n",
       "                                 [0.482, 0.505, 0.125, ..., 0.   , 0.857, 1.   ],\n",
       "                                 [0.52 , 0.504, 0.125, ..., 0.   , 0.857, 1.   ],\n",
       "                                 ...,\n",
       "                                 [0.779, 0.541, 0.375, ..., 0.   , 0.714, 0.   ],\n",
       "                                 [0.016, 0.527, 0.375, ..., 0.   , 0.714, 0.   ],\n",
       "                                 [0.047, 0.556, 0.375, ..., 0.   , 0.714, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([3, 3, 3, ..., 2, 2, 2])}),\n",
       "             '6': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.045, 0.479, 0.625, ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.097, 0.498, 0.625, ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.138, 0.542, 0.625, ..., 0.   , 0.905, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.032, 0.49 , 0.625, ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.066, 0.464, 0.625, ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.139, 0.448, 0.625, ..., 0.   , 0.905, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([3, 3, 3, ..., 2, 2, 2])}),\n",
       "             '7': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.843, 0.453, 0.5  , ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.832, 0.456, 0.5  , ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.044, 0.521, 0.5  , ..., 0.   , 0.905, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.386, 0.626, 0.125, ..., 0.   , 0.714, 0.   ],\n",
       "                                 [0.391, 0.608, 0.125, ..., 0.   , 0.714, 0.   ],\n",
       "                                 [0.395, 0.607, 0.125, ..., 0.   , 0.714, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([3, 3, 3, ..., 2, 2, 2])}),\n",
       "             '8': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.192, 0.485, 0.375, ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.22 , 0.467, 0.375, ..., 0.   , 0.905, 0.   ],\n",
       "                                 [0.239, 0.465, 0.375, ..., 0.   , 0.905, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.447, 0.473, 0.625, ..., 0.   , 0.952, 0.   ],\n",
       "                                 [0.451, 0.498, 0.625, ..., 0.   , 0.952, 0.   ],\n",
       "                                 [0.483, 0.509, 0.625, ..., 0.   , 0.952, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([3, 3, 3, ..., 1, 1, 1])}),\n",
       "             '9': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'x_test': array([[0.373, 0.481, 0.375, ..., 0.   , 0.714, 1.   ],\n",
       "                                 [0.402, 0.478, 0.375, ..., 0.   , 0.714, 1.   ],\n",
       "                                 [0.407, 0.474, 0.375, ..., 0.   , 0.714, 1.   ],\n",
       "                                 ...,\n",
       "                                 [0.488, 0.601, 0.5  , ..., 1.   , 0.762, 0.   ],\n",
       "                                 [0.604, 0.601, 0.5  , ..., 1.   , 0.762, 0.   ],\n",
       "                                 [0.583, 0.597, 0.5  , ..., 1.   , 0.762, 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 3, 3, 3]),\n",
       "                          'y_test': array([3, 3, 3, ..., 1, 1, 1])}),\n",
       "             '10': defaultdict(list,\n",
       "                         {'x_train': array([[0.043, 0.503, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.06 , 0.537, 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 [0.121, 0.53 , 0.5  , ..., 1.   , 0.381, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.488, 0.601, 0.5  , ..., 1.   , 0.762, 0.   ],\n",
       "                                 [0.604, 0.601, 0.5  , ..., 1.   , 0.762, 0.   ],\n",
       "                                 [0.583, 0.597, 0.5  , ..., 1.   , 0.762, 0.   ]]),\n",
       "                          'x_test': array([[0.707, 0.659, 0.   , ..., 0.   , 0.571, 0.   ],\n",
       "                                 [0.74 , 0.641, 0.   , ..., 0.   , 0.571, 0.   ],\n",
       "                                 [0.74 , 0.643, 0.   , ..., 0.   , 0.571, 0.   ],\n",
       "                                 ...,\n",
       "                                 [0.609, 0.579, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.528, 0.546, 0.5  , ..., 0.   , 0.81 , 0.   ],\n",
       "                                 [0.644, 0.538, 0.5  , ..., 0.   , 0.81 , 0.   ]]),\n",
       "                          'y_train': array([1, 1, 1, ..., 1, 1, 1]),\n",
       "                          'y_test': array([2, 2, 2, ..., 3, 3, 3])})})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918b5f5",
   "metadata": {},
   "source": [
    "## Load the tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6621539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dd_fix_demo-tknn_cls--shuffled:False--exclude at risk:0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e9b413d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('n_neighbors', 2), ('p', 1.0066508992288465)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tuned_params = load_a_dict(\n",
    "    name='dd_fix_demo-knn_cls--shuffled:False--exclude at risk:0',\n",
    "    save_path=configs.params_path\n",
    "        )\n",
    "tuned_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9abedb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsTimeSeriesClassifier(n_neighbors=10, verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mdl = tslearn.neighbors.KNeighborsTimeSeriesClassifier(\n",
    "    n_neighbors=10,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "mdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e356bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[\"6\"][\"x_train\"]\n",
    "x_test = data[\"6\"][\"x_test\"]\n",
    "y_train = data[\"6\"][\"y_train\"]\n",
    "y_test = data[\"6\"][\"y_test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0116ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['Norm', 'At-risk', 'Dyslexic']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eba6e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "\n",
    "# mdl = load(configs.models_path.joinpath(configs.specifier+\".joblib\"))\n",
    "# mdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74d19bfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# results = load_a_dict(\n",
    "#     name=configs.specifier,\n",
    "#     save_path=configs.results_path,\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     i = str(i)\n",
    "#     y_test_ = results[i][\"y_test\"]\n",
    "#     y_pred_ = results[i][\"y_pred\"]\n",
    "#     y_prob_ = results[i][\"y_pred_prob\"]\n",
    "    \n",
    "#     cm = sklearn.metrics.confusion_matrix(\n",
    "#     y_true=y_test_, \n",
    "#     y_pred=y_pred_\n",
    "#     )\n",
    "    \n",
    "#     disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "#                               display_labels=class_names\n",
    "#                              )\n",
    "#     disp.plot()\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     print(\n",
    "#         \"Kappa:\", sklearn.metrics.cohen_kappa_score(y1=y_test_, y2=y_pred_),\n",
    "        \n",
    "#         \"AUC ROC:\", sklearn.metrics.roc_auc_score(y_test_, y_prob_,\n",
    "#                                                   multi_class=\"ovr\",\n",
    "#                                                   average=\"weighted\")\n",
    "#     )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40c0873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print_the_evaluated_results(\n",
    "#     results=results, \n",
    "#     learning_method=learning_method\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a9e7e1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 306. GiB for an array with shape (202815, 202815) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_156570/288289831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_Jan2022/lib/python3.9/site-packages/tslearn/neighbors/neighbors.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             self._X_fit = numpy.zeros((self._ts_fit.shape[0],\n\u001b[0m\u001b[1;32m    494\u001b[0m                                        self._ts_fit.shape[0]))\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 306. GiB for an array with shape (202815, 202815) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mdl.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e539a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"model fitted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50104864",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.predict_proba(x_test[5:10:, :])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.predict(x_test[5:10:, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "disp = sklearn.metrics.plot_confusion_matrix(\n",
    "    mdl, x_test, y_test, \n",
    "    display_labels=class_names, \n",
    "    cmap=plt.cm.Blues, \n",
    "    xticks_rotation='vertical'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sklearn.metrics.roc_auc_score(y_test, \n",
    "                              mdl.predict_proba(x_test),\n",
    "                              multi_class=\"ovr\",\n",
    "                              average=\"weighted\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bf893",
   "metadata": {},
   "source": [
    "- \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991c75e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(list(x_org.columns)) == x_test.shape[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(mdl.predict, x_test, feature_names=list(x_org.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee30593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shap_values = explainer(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Shap values are determined!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a32aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_test.shape, x_test.shape, shap_values.values.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa473f2d",
   "metadata": {},
   "source": [
    "- what does row explain?  sorted features' importance in ascending order, low to high.\n",
    "- what does each dot explain? data points\n",
    "- what does color explain? data points per feature value\n",
    "\n",
    "Interpret: \n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values, \n",
    "#                   x_test, \n",
    "#                   plot_type=\"bar\", \n",
    "#                   class_names=class_names, \n",
    "#                   feature_names=list(x_org.columns),\n",
    "#                   alpha=0.1,\n",
    "#                   color_bar=True,\n",
    "#                   color_bar_label=True\n",
    "#                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829bea0",
   "metadata": {},
   "source": [
    "### Shap bar plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.plots.bar(shap_values, max_display=99, show=False)\n",
    "# plt.gcf()\n",
    "# plt.savefig(\"plots/bar.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01191600",
   "metadata": {},
   "source": [
    "\n",
    "- The bar plot above depicgts the Mean Absolute SHAP (MAS) values for each feature across the entire data. MAS, on average, quantifies, the magnitude of each feature's contribution towards the predicted class labels. The higher the MAS value for a a feature the more influential that feature is.\n",
    "\n",
    "\n",
    "- The gender SHAP values sums up to 0.35 turning it two one of the most influentioal features. \n",
    "- IQ, Age and the third and fourth grades are the other important features in predicing the class labels.\n",
    "- Althoght the remaining features have less significant SHAP values, still they all plan a role in predicting class labels.\n",
    "\n",
    "- More info on beeswarm-bar plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c183018",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf()\n",
    "shap.plots.bar(shap_values.abs.max(0), max_display=99, show=False)\n",
    "plt.subplot(2, 1, 2)\n",
    "shap.plots.beeswarm(\n",
    "    shap_values.abs, color=\"shap_red\", max_display=99, show=False, plot_size=None\n",
    ")\n",
    "ax = plt.gca()\n",
    "masv = {}\n",
    "\n",
    "for feature in ax.get_yticklabels():\n",
    "    name = feature.get_text()\n",
    "    col_ind = x_org.columns.get_loc(name)\n",
    "    mean_abs_sv = np.mean(np.abs(shap_values.values[:, col_ind]))\n",
    "    masv[name] = mean_abs_sv\n",
    "ax.scatter(\n",
    "    masv.values(),\n",
    "    [i for i in range(len(x_org.columns))],\n",
    "    zorder=99,\n",
    "    label=\"Mean Absolute SHAP Value\",\n",
    "    c=\"k\",\n",
    "    marker=\"|\",\n",
    "    linewidths=3,\n",
    "    s=100,\n",
    ")\n",
    "ax.legend(frameon=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.savefig(\"plots/bar_beeswarm.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bb721",
   "metadata": {},
   "source": [
    "##### Beeswarm-bar plot: \n",
    "\n",
    "In addition to observe the same pattern on the relative importannce of features, one can observe that:\n",
    "\n",
    "- There are quite a few sixth grade participants with very high SHAP values despite of its low MAS value in general.\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b4dae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### SHAP Beeswarm Plots\n",
    "\n",
    "\n",
    "- Permutation importance numerically measures the importance of features. This simplifies the comparison between features.  However, the considered interaction between features during the features importance determination process, as can be considered a severe drawback of this method. SHAP summary plots give us a birds-eye view of feature importance and what is driving it. \n",
    "\n",
    "- The points are distributed horizontally along the x-axis according to their SHAP value. In places where there is a high density of SHAP values, the points are stacked vertically. Examining how the SHAP values are distributed reveals how a variable may influence the model's predictions.\n",
    "\n",
    "- The colour bar corresponds to the raw values (not to be confused with the SHAP values) of the variables for each instance (i.e. point) on the graph. If the value of a variable for a particular instance is relatively high, it appears as a red dot. Relatively low variable values appear as blue dots. Examining the color distribution horizontally along the x-axis for each variable provides insights into the general relationship between a variable's raw values and its SHAP values.\n",
    "\n",
    "\n",
    "- These (the columns) are the input variables, ranked from top to bottom by their mean absolute SHAP values for the entire dataset. Note: this ranking is exactly the same as for the bar plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1227ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values=shap_values.values, \n",
    "                  features=x_test,\n",
    "                  class_names=[\"Norm\", \"at-risk\", \"Dyslexic\"],\n",
    "                  feature_names=list(x_org.columns), \n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84189bc7",
   "metadata": {},
   "source": [
    "\n",
    "- None-female (male) students have high SHAP values, implying the significance of this feature on prediction results. \n",
    "\n",
    "\n",
    "- Only the two extremes of students' \"IQ\" have direct impacts models prediction.\n",
    "\n",
    "\n",
    "- Similar to IQ features, only the two extremes of \"Age\" feature plays an important role in models prediction.\n",
    "\n",
    "\n",
    "- Most of the 3rd and 4th grade students, unlike the rest of grades, have high SHAP values which demostrates the importance of these two features.\n",
    "\n",
    "\n",
    "- Fixation along Y-axis is more important than X-axis. \n",
    "\n",
    "\n",
    "- The 6th grade has no low impact on model's prediction result. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86149a27",
   "metadata": {},
   "source": [
    "### SHAP Dependence Contribution Plots\n",
    "\n",
    "A dependence plot is a scatter plot that shows the effect a single feature has on the predictions made by the model. SHAP dependence contribution plots provide a similar insight to PDP's, but they add a lot more detail.\n",
    "\n",
    "\n",
    "- Each dot is a single prediction (row) from the dataset.\n",
    "- The x-axis is the actual value from the dataset.\n",
    "- The y-axis is the SHAP value for that feature, which represents how much knowing that feature’s value changes the output of the model for that sample’s prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "fig, ax = plt.subplots(1, n, figsize=(15, 5))\n",
    "\n",
    "for i, (k, v) in enumerate(sorted(masv.items(), key=lambda x: x[1], reverse=True)):\n",
    "    if i < n:\n",
    "        shap.plots.scatter(shap_values[:, k], ax=ax[i], show=False, alpha=0.6)\n",
    "        ax[i].grid(axis=\"y\")\n",
    "        if i != 0:\n",
    "            ax[i].set_ylabel(\"\")\n",
    "            ax[i].spines[\"left\"].set_visible(False)\n",
    "            ax[i].set_ylim(ax[0].get_ylim())\n",
    "            ax[i].set_yticklabels([\"\" for _ in range(len(ax[0].get_yticks()))])\n",
    "        else:\n",
    "            ax[i].set_ylabel(\"SHAP value\")\n",
    "# fig.savefig(\"plots/scatter_top5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28143e89",
   "metadata": {},
   "source": [
    "\n",
    "- The vertical spread of SHAP values at a fixed raw variable value is due to interaction effects with other variables. For example, here we see that sex_1 equal to unity (female) can have SHAP values that range from $-0.6 to 0.15$ depending on the other data for those particular instances. \n",
    "\n",
    "\n",
    "- The shapes of the distributions of points provide insights into the relationship between a variable's values and its SHAP values. We cannot see any specific relation between any individual feature and its importance (its SHAP values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 5\n",
    "# fig, ax = plt.subplots(1, n, figsize=(15, 5))\n",
    "\n",
    "# for i, (k, v) in enumerate(sorted(masv.items(), key=lambda x: x[1], reverse=True)):\n",
    "#     if i < n:\n",
    "#         shap.plots.scatter(shap_values[:, k], ax=ax[i], show=False, alpha=0.6)\n",
    "#         ax[i].grid(axis=\"y\")\n",
    "#         if i != 0:\n",
    "#             ax[i].set_ylabel(\"\")\n",
    "#             ax[i].spines[\"left\"].set_visible(False)\n",
    "#             ax[i].set_ylim(ax[0].get_ylim())\n",
    "#             ax[i].set_yticklabels([\"\" for _ in range(len(ax[0].get_yticks()))])\n",
    "#         else:\n",
    "#             ax[i].set_ylabel(\"SHAP value\")\n",
    "# # fig.savefig(\"plots/scatter_top5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaacaef",
   "metadata": {},
   "source": [
    "##### Dependece plots:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b241b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455ecd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(x_test.shape[1]):\n",
    "    fig, ax = plt.subplots()\n",
    "    shap.plots.scatter(shap_values[:, i], color=shap_values, ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19adcc",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f290157",
   "metadata": {},
   "source": [
    "\n",
    "## Individual force plots of 3 randomly selected samples of each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "normals = np.where(y_test == 1)[0]\n",
    "at_risks = np.where(y_test == 2)[0]\n",
    "dyslexics = np.where(y_test == 3)[0]\n",
    "\n",
    "\n",
    "\n",
    "n_size = 5\n",
    "np.random.seed(43)\n",
    "normals_rnd = np.random.choice(normals, n_size)\n",
    "at_risks_rnd = np.random.choice(at_risks, n_size)\n",
    "dyslexics_rnd = np.random.choice(dyslexics, n_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "normals_rnd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b851a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risks_rnd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d17f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dyslexics_rnd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in normals_rnd:\n",
    "    shap.plots.force(shap_values[n], show=False, matplotlib=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e99272",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in at_risks_rnd:\n",
    "    shap.plots.force(shap_values[r], show=False, matplotlib=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddb7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dyslexics_rnd:\n",
    "    shap.plots.force(shap_values[d], show=False, matplotlib=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fceca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de135b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Jan2022",
   "language": "python",
   "name": "venv_jan2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
