{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9d2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import shap \n",
    "import pickle\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a8aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from dd_package.data.dyslexia_data import DyslexiaData\n",
    "from dd_package.data.preprocess import preprocess_data\n",
    "\n",
    "from dd_package.models.regression_estimators import RegressionEstimators\n",
    "\n",
    "from dd_package.common.utils import save_a_dict, load_a_dict\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334f200",
   "metadata": {},
   "source": [
    "# fix-demo-Fcls-mm:\n",
    "\n",
    "- Chosen model: **Random Forest**\n",
    "\n",
    "- Note: MLP was being trained while I decided to conduct this experiment \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f70fb3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b8b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dd = DyslexiaData(path=\"../../datasets/\", n_repeats=5)\n",
    "to_exclude_at_risk = 0\n",
    "\n",
    "\n",
    "\n",
    "data_name = \"dd_fix_demo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fb281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f4789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Demo data: \n",
      "  dyslexia (72, 9)\n",
      "  norm (213, 9)\n",
      "  risk (22, 9)\n",
      " \n",
      "Loading Fixation report data:\n",
      "  dyslexia (59770, 7)\n"
     ]
    }
   ],
   "source": [
    "if data_name == \"dd_demo\":\n",
    "    # dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "    _ = dd.get_demo_datasets()  # demos and phonological (which is initially part of demo)\n",
    "    demo_phono = dd.concat_classes_demo()\n",
    "\n",
    "    # The optimize way to exclude at-risk class\n",
    "    if to_exclude_at_risk == 1:\n",
    "        to_exclude_at_risk = True\n",
    "        demo_phono = demo_phono.loc[demo_phono.Group != 2]\n",
    "\n",
    "    df_data_to_use = demo_phono.loc[:, [\n",
    "                                           'Group', 'SubjectID', 'Sex', 'Grade', 'Age', 'IQ', 'Reading_speed',\n",
    "                                       ]]\n",
    "    c_features = ['Sex', 'Grade', ]\n",
    "    indicators = ['SubjectID', ]\n",
    "    targets = [\"Group\", \"Reading_speed\", ]\n",
    "\n",
    "elif data_name == \"dd_fix_demo\":\n",
    "    # dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "    _ = dd.get_demo_datasets()  # demos\n",
    "    _ = dd.get_fix_datasets()  # fixes\n",
    "\n",
    "    # concatenate pd.dfs to a pd.df\n",
    "    fix = dd.concat_classes_fix()\n",
    "    demo_phono = dd.concat_classes_demo()\n",
    "\n",
    "    # The optimize way to exclude at-risk class\n",
    "    if to_exclude_at_risk == 1:\n",
    "        to_exclude_at_risk = True\n",
    "        fix = fix.loc[fix.Group != 2]\n",
    "        demo_phono = demo_phono.loc[demo_phono.Group != 2]\n",
    "\n",
    "    fix_demo = dd.concat_dfs(\n",
    "        df1=fix,\n",
    "        df2=demo_phono,\n",
    "        features1=fix.columns,\n",
    "        features2=[\n",
    "            \"Sex\", \"Grade\", \"Age\", \"IQ\", \"Reading_speed\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df_data_to_use = fix_demo\n",
    "    c_features = ['Sex', 'Grade', ]\n",
    "    indicators = [\n",
    "        'SubjectID', 'Sentence_ID', 'Word_Number',\n",
    "    ]\n",
    "\n",
    "    targets = [\"Group\", \"Reading_speed\", ]\n",
    "    \n",
    "elif data_name == \"dd_fix\":\n",
    "\n",
    "    # dict of dicts, s.t each dict contains pd.df of a class, e.g normal\n",
    "    _ = dd.get_fix_datasets()  # fixes\n",
    "    # concatenate pd.dfs to a pd.df\n",
    "    fix = dd.concat_classes_fix()\n",
    "\n",
    "    # The optimize way to exclude at-risk class\n",
    "    if to_exclude_at_risk == 1:\n",
    "        to_exclude_at_risk = True\n",
    "        fix = fix.loc[fix.Group != 2]\n",
    "\n",
    "    df_data_to_use = fix\n",
    "    c_features = None\n",
    "    indicators = [\n",
    "        'SubjectID', 'Sentence_ID', 'Word_Number',\n",
    "    ]\n",
    "\n",
    "    targets = [\"Group\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c67800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_to_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa773a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_org, y_org = dd.get_onehot_features_targets(\n",
    "    data=df_data_to_use,\n",
    "    c_features=c_features,\n",
    "    indicators=indicators,\n",
    "    targets=targets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4beffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_name = \"MLP_cls\"\n",
    "\n",
    "if estimator_name.split(\"_\")[-1] == \"reg\":\n",
    "    learning_method = \"regression\"\n",
    "    y = y_org.Reading_speed.values\n",
    "\n",
    "elif estimator_name.split(\"_\")[-1] == \"cls\":\n",
    "    learning_method = \"classification\"\n",
    "    y = y_org.Group.values\n",
    "\n",
    "elif estimator_name.split(\"_\")[-1] == \"clu\":\n",
    "    from dd_package.models.clustering_estimators import ClusteringEstimators\n",
    "    y = y_org.Group.values\n",
    "else:\n",
    "    assert False, \"Undefined algorithm and thus undefined target values\"\n",
    "    \n",
    "print(\"learning_method:\", learning_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25adc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_data(x=x_org, pp=\"mm\")  # only x is standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dd.get_stratified_train_test_splits(\n",
    "        x=x, y=y,\n",
    "        labels=y_org.Group.values,\n",
    "        to_shuffle=True,\n",
    "        n_splits=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918b5f5",
   "metadata": {},
   "source": [
    "## Load the tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d802f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_name == \"dd_fix_demo\":\n",
    "    print(data_name)\n",
    "    with open(\"../../Params/dd_fix_demo-rf_cls--shuffled_True--exclude at risk_0.pickle\", \"rb\") as fp:\n",
    "        tuned_params = pickle.load(fp)\n",
    "        \n",
    "elif data_name == \"dd_demo\":\n",
    "    print(data_name)\n",
    "    with open(\"../../Params/dd_demo-rf_cls--shuffled_True--exclude at risk_0.pickle\", \"rb\") as fp:\n",
    "        tuned_params = pickle.load(fp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abedb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=tuned_params[\"n_estimators\"], \n",
    "    min_samples_leaf=tuned_params[\"min_samples_leaf\"],\n",
    "    min_samples_split=tuned_params[\"min_samples_split\"],\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e356bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[\"1\"][\"x_train\"]\n",
    "x_test = data[\"1\"][\"x_test\"]\n",
    "y_train = data[\"1\"][\"y_train\"]\n",
    "y_test = data[\"1\"][\"y_test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e539a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50104864",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.predict_proba(x_test[70:75:, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.predict(x_test[70:75:, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Norm', 'At-risk', 'Dyslexic']\n",
    "\n",
    "disp = sklearn.metrics.plot_confusion_matrix(\n",
    "    mdl, x_test, y_test, \n",
    "    display_labels=class_names, \n",
    "    cmap=plt.cm.Blues, \n",
    "    xticks_rotation='vertical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bf893",
   "metadata": {},
   "source": [
    "- acceptable performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991c75e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(list(x_org.columns)) == x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(mdl.predict, x_test, feature_names=list(x_org.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee30593",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Shap values are determined!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a32aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape, x_test.shape, shap_values.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1262888",
   "metadata": {},
   "source": [
    "### SHAP Summary Plots\n",
    "\n",
    "\n",
    "Permutation importance numerically measures the importance of features. This simplifies the comparison between features.  However, the considered interaction between features during the features importance determination process, as can be considered a severe drawback of this method. SHAP summary plots give us a birds-eye view of feature importance and what is driving it. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e34dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values=shap_values.values, \n",
    "                  features=x_test,\n",
    "                  class_names=[\"Norm\", \"at-risk\", \"Dyslexic\"],\n",
    "                  feature_names=list(x_org.columns), \n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa473f2d",
   "metadata": {},
   "source": [
    "- what does row explain?  sorted features' importance in ascending order, low to high.\n",
    "- what does each dot explain? data points\n",
    "- what does color explain? data points per feature value\n",
    "\n",
    "Interpret: \n",
    "\n",
    "\n",
    "- Generally, the 4th grade and the age are the most important features. \n",
    "\n",
    "\n",
    "- There are few 6th grade students with negative impact (i.e decreasing the prediction by 0.1)\n",
    "\n",
    "- Except for one student with high IQ, the rest of students' IQ do not affect the prediction results significantly.\n",
    "\n",
    "- We can observe very similar pattern for the rest of featuress \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, \n",
    "                  x_test, \n",
    "                  plot_type=\"bar\", \n",
    "                  class_names=class_names, \n",
    "                  feature_names=list(x_org.columns),\n",
    "                  alpha=0.1,\n",
    "                  color_bar=True,\n",
    "                  color_bar_label=True\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01191600",
   "metadata": {},
   "source": [
    "### Shap bar plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86149a27",
   "metadata": {},
   "source": [
    "### SHAP Dependence Contribution Plots\n",
    "\n",
    "A dependence plot is a scatter plot that shows the effect a single feature has on the predictions made by the model. SHAP dependence contribution plots provide a similar insight to PDP's, but they add a lot more detail.\n",
    "\n",
    "\n",
    "- Each dot is a single prediction (row) from the dataset.\n",
    "- The x-axis is the actual value from the dataset.\n",
    "- The y-axis is the SHAP value for that feature, which represents how much knowing that feature’s value changes the output of the model for that sample’s prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf051376",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    -1, shap_values=shap_values.values, \n",
    "    features=x_test,\n",
    "    feature_names=x_org.columns,\n",
    "    \n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19adcc",
   "metadata": {},
   "source": [
    "- various male students at the 4th grade has high positive impacts on model predictions, also there several female students from other grades which have high negative importance on model's prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba6f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Jan2022",
   "language": "python",
   "name": "venv_jan2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
